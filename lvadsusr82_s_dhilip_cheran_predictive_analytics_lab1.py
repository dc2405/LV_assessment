# -*- coding: utf-8 -*-
"""LVADSUSR82_S DHILIP CHERAN_predictive analytics_LAB1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hn-wfkhlbsajC0sdwlNVtqhAlsIxKMHP
"""

#Step 1 Reading the data:
import pandas as pd
data = pd.read_csv("/content/loan_approval.csv")

#Step 2 Data Preprocessing:
# Handling missing values:
data.fillna(data.mean(), inplace=True)

# Handling outliers:
from scipy.stats.mstats import winsorize
data["income"] = winsorize(data["income"], limits=[0.05, 0.05])

# Encoding categorical variables(using one-hot encoding)
data = pd.get_dummies(data, columns=["education_level", "employment_status"])

#STEP 3 Exploratory Data Analysis (EDA):

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Descriptive Statistics
print("Descriptive Statistics:")
print(data.describe())

# Class Distribution
print("\nClass Distribution:")
print(data['Loan_Status'].value_counts())

# Correlation Heatmap
print("\nCorrelation Heatmap:")
plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()

# Pairplot
print("\nPairplot:")
sns.pairplot(data, hue='Loan_Status', diag_kind='kde')
plt.title("Pairplot")
plt.show()

# Distribution of Numerical Features by Loan Status
print("\nDistribution of Numerical Features by Loan Status:")
numerical_features = data.select_dtypes(include=['int64', 'float64']).columns
for feature in numerical_features:
    plt.figure(figsize=(8, 6))
    sns.histplot(data=data, x=feature, hue='Loan_Status', kde=True, bins=20, alpha=0.5)
    plt.title(f"Distribution of {feature} by Loan Status")
    plt.xlabel(feature)
    plt.ylabel("Frequency")
    plt.legend(title="Loan Status", loc='upper right')
    plt.show()

# Descriptive statistics
print(data.describe())

# Shape of the data
print(data.shape)

#STEP 4 Model Training & Testing:

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

#Splitting the dataset into features (X) and target variable (y)
X = data.drop("loan_status", axis=1)
y = data["loan_status"]

# Split the data into training and testing sets:
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions on the testing set
predictions = model.predict(X_test)

#Step 5 Model Evaluation Metrics:

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Calculating accuracy:
accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)

# Calculate other evaluation metrics
print("Confusion Matrix:\n", confusion_matrix(y_test, predictions))
print("Classification Report:\n", classification_report(y_test, predictions))
print("ROC-AUC Score:", roc_auc_score(y_test, model.predict_proba(X_test)[:,1]))