# -*- coding: utf-8 -*-
"""LVADSUSR82_S DHILIP CHERAN_predictive analytics_LAB2ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wm6rcq8SfEy6W9X4SoJ9eudJOB1L79yZ
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Step 1: Read Data
data = pd.read_csv("/content/auto-mpg.csv")

# Step 2: Data Preprocessing
# Handling missing values
data.fillna(data.mean(), inplace=True)

# Handling outliers
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from scipy.stats import zscore

z_scores = zscore(data.drop("mpg", axis=1))

threshold = 3
outliers = (abs(z_scores) > threshold).any(axis=1)
data_no_outliers = data[~outliers]


# Step 3: Exploratory Data Analysis
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Descriptive Statistics
print("Descriptive Statistics:")
print(data.describe())

# Correlation Heatmap
print("\nCorrelation Heatmap:")
plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()

# Pairplot
print("\nPairplot:")
sns.pairplot(data, diag_kind='kde')
plt.title("Pairplot")
plt.show()

# Distribution of Target Variable (mpg)
print("\nDistribution of Target Variable (mpg):")
plt.figure(figsize=(8, 6))
sns.histplot(data['mpg'], bins=20, kde=True)
plt.title("Distribution of Target Variable (mpg)")
plt.xlabel("Miles Per Gallon (mpg)")
plt.ylabel("Frequency")
plt.show()

# Boxplot of Numerical Features
print("\nBoxplot of Numerical Features:")
plt.figure(figsize=(12, 8))
sns.boxplot(data=data.drop("mpg", axis=1), orient="h")
plt.title("Boxplot of Numerical Features")
plt.show()

print("Descriptive Statistics:")
print(data.describe())

print("\nShape of the Data:")
print(data.shape)
print("Descriptive Statistics (After Handling Outliers):")
print(data_no_outliers.describe())

print("\nShape of the Data (After Handling Outliers):")
print(data_no_outliers.shape)

# Step 4: Model Training & Testing
# Split the dataset into features (X) and target variable (y)
X = data_no_outliers.drop("mpg", axis=1)
y = data_no_outliers["mpg"]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions on the testing set
predictions = model.predict(X_test)

# Step 5: Model Evaluation Metrics
mse = mean_squared_error(y_test, predictions)
rmse = mean_squared_error(y_test, predictions, squared=False)
mae = mean_absolute_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

print("\nMean Squared Error (After Handling Outliers):", mse)
print("Root Mean Squared Error (After Handling Outliers):", rmse)
print("Mean Absolute Error (After Handling Outliers):", mae)
print("R-squared Score (After Handling Outliers):", r2)